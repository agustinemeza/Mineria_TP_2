
# TP 02 - MD II: Pipeline de Analytics para Cloud Provider

## üìã Descripci√≥n

Pipeline completo de ingesta, procesamiento y serving de datos para analytics de un proveedor cloud, implementado en **Google Colab** con **PySpark** y **AstraDB (Cassandra)**, siguiendo las especificaciones del TP 02.

La soluci√≥n implementa una arquitectura tipo **Lambda** con zonas:
**Landing ‚Üí Bronze ‚Üí Silver ‚Üí Gold ‚Üí Serving (Cassandra)**.

---

### üß± 1. BATCH A BRONZE ‚Äì **COMPLETADO**

**Objetivo:** Ingestar al menos 3 maestros desde archivos CSV a Parquet particionado.

**‚úÖ Acciones implementadas:**

- ‚úÖ Lectura de:
  - `customers_orgs.csv`
  - `users.csv`
  - `billing_monthly.csv`
- ‚úÖ Aplicaci√≥n de esquemas tipados:
  - `created_at` como `TimestampType`
  - montos como `DecimalType`
  - fechas de billing como `DateType`
- ‚úÖ Columnas t√©cnicas agregadas:
  - `ingest_ts`: timestamp de ingesta
  - `source_file`: nombre del archivo origen
  - `ingest_date`: fecha de ingesta para particionado
- ‚úÖ Deduplicaci√≥n por clave natural:
  - `customers`: por `org_id`
  - `users`: por `user_id`
  - `billing`: por `billing_id`
- ‚úÖ Almacenamiento en formato **Parquet particionado por `ingest_date`** en:
  - `bronze/customers/ingest_date=YYYY-MM-DD/`
  - `bronze/users/ingest_date=YYYY-MM-DD/`
  - `bronze/billing/ingest_date=YYYY-MM-DD/`

---

### üîÅ 2. STREAMING A BRONZE ‚Äì **COMPLETADO**

**Objetivo:** Leer eventos de uso en tiempo real desde `usage_events_stream/*.jsonl` y estandarizarlos en Bronze.

**‚úÖ Acciones implementadas:**

- ‚úÖ Definici√≥n de `usage_events_schema` con tipos expl√≠citos:
  - `event_timestamp` como `TimestampType`
  - `cost_usd_increment` como `DecimalType(10,4)`
  - `genai_tokens` como `LongType`
  - `carbon_kg` como `DecimalType(10,6)`
- ‚úÖ Implementaci√≥n de **Structured Streaming** (versi√≥n de demo):
  - `readStream` sobre `usage_events_stream/*.jsonl`
  - `withWatermark("event_timestamp", "10 minutes")` para manejo de datos tard√≠os
  - `dropDuplicates(["event_id"])` para evitar duplicados por reenv√≠os
  - columnas t√©cnicas: `ingest_ts`, `source_file`, `ingest_date`, `event_date`
- ‚úÖ Escritura del stream en Bronze:
  - Formato **Parquet**
  - `outputMode("append")`
  - `checkpointLocation` configurado en `bronze/checkpoints/usage_events`
  - particionado por `ingest_date`
- ‚úÖ Adicionalmente, se incluy√≥ una versi√≥n batch para simular streaming en Colab, manteniendo la misma l√≥gica de transformaci√≥n.

---

### üßº 3. CAPA SILVER (Limpieza y Enriquecimiento) ‚Äì **COMPLETADO**

**Objetivo:** Unir eventos de uso con datos maestros, crear features y aplicar reglas de calidad.

**‚úÖ Enriquecimiento:**

- ‚úÖ Join de `usage_events` (Bronze) con `customers` (Bronze) por `org_id`.
- ‚úÖ Campos enriquecidos:
  - `org_name`
  - `industry`
  - `customer_tier`

**‚úÖ Features calculadas:**

1. `daily_cost_usd`  
   - Suma diaria de `cost_usd_increment` por (`org_id`, `event_date`).

2. `requests`  
   - Cantidad de requests procesados cuando `unit = 'count'`, 0 en otros casos.

3. `genai_tokens_clean`  
   - Limpieza de `genai_tokens` con `coalesce(..., 0)` para evitar NULLs.

4. `carbon_kg_clean`  
   - Limpieza de `carbon_kg` con `coalesce(..., 0.0)` para evitar NULLs.

5. `cost_anomaly_flag`  
   - Flag booleano que marca `True` cuando `cost_usd_increment < 0`.

**‚úÖ Reglas de calidad (Data Quality):**

1. `event_id` no nulo ni vac√≠o:
   - `event_id IS NOT NULL AND event_id != ''`

2. `cost_usd_increment ‚â• -0.01`:
   - evita outliers muy negativos.

3. `unit` no nulo cuando existe `value`:
   - si hay `value` y `unit` es NULL ‚Üí va a cuarentena.

**‚úÖ Cuarentena:**

- Registros que no cumplen alguna regla se env√≠an a **Quarantine**.
- Se manejan **dos canales**:
  - Registros con reglas fallidas (campos inv√°lidos).
  - Registros que ten√≠an `event_date` nulo (evitan partici√≥n `__HIVE_DEFAULT_PARTITION__`).
- Se generan **muestras de cuarentena**:
  - `quarantine/usage_events/` con todos los rechazados.
  - `quarantine/samples/` con un subconjunto (ej. primeros 20) para an√°lisis.

**‚úÖ Escritura de Silver:**

- Silver se escribe en:
  - `silver/usage_events/`
- Formato **Parquet**
- Modo `overwrite` (para facilitar idempotencia)
- Sin particionar adicionalmente (para evitar errores por particiones corruptas).

---

### üìä 4. CAPA GOLD (Mart FinOps) ‚Äì **COMPLETADO**

**Objetivo:** Construir un mart anal√≠tico de FinOps para uso diario.

**‚úÖ Mart generado: `org_daily_usage_by_service`**

**Clave de agrupaci√≥n:**

- `org_id`
- `org_name`
- `service_name`
- `event_date`

**‚úÖ Aspectos t√©cnicos:**

- Se agrega columna t√©cnica `load_ts` al mart.
- Se escribe en:
  - `gold/org_daily_usage_by_service/`
- Formato **Parquet**
- Modo `overwrite`
- **Particionado por `event_date`**, permitiendo:
  - queries eficientes por rango de fechas
  - administraci√≥n segmentada por d√≠a.

---

### DATOS DE PRUEBA 

Los datos de prueba se encuentran en:
https://drive.google.com/drive/folders/1BRdZ05vFzLtfBP-nSTKS4Ewm24ILpZmw?usp=drive_link

---

### üóÉÔ∏è 5. SERVING EN CASSANDRA (AstraDB) ‚Äì **COMPLETADO**

**Objetivo:** Modelar una tabla orientada a consulta (query-first) y cargar el Mart Gold.

**‚úÖ Modelo de datos en Cassandra (AstraDB):**

Keyspace utilizado: `default_keyspace`.

Tabla:

```sql
CREATE TABLE IF NOT EXISTS default_keyspace.org_daily_usage (
    org_id text,
    date date,
    service_name text,
    org_name text,
    total_cost_usd decimal,
    total_requests bigint,
    total_genai_tokens bigint,
    total_carbon_kg decimal,
    total_events bigint,
    avg_cost_per_event decimal,
    load_ts timestamp,
    PRIMARY KEY ((org_id, date), service_name)
) WITH CLUSTERING ORDER BY (service_name ASC);

** METRICAS CALCULADAS ** 

-- Total de costo por organizaci√≥n en un rango de fecha especifico

USE default_keyspace;

SELECT org_id,
    sum(total_cost_usd) as cost_periodo 
FROM org_daily_usage
WHERE org_id = 'ORG001'
  AND date >= '2022-01-01'
  AND date <= '2022-01-31'
ALLOW FILTERING;

-- Consumo de un per√≠odo especifico 

USE default_keyspace;

SELECT org_id, date, service_name, total_cost_usd
FROM org_daily_usage
WHERE org_id = 'ORG001'
  AND date >= '2022-01-01'
  AND date <= '2022-01-31'
ALLOW FILTERING;
